<!doctype html><html lang=zh-cn dir=ltr>
<head><meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成 在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传">
<title>全连接神经网络浅析</title>
<link rel=canonical href=https://blog.nightspace.dynv6.net/post/fully-neural-network/>
<link rel=stylesheet href=/scss/style.min.ff300df33b80e2ac49809c825614392ed1c7b27591d65d3c4043602cd162e25f.css>
<script src=https://gcore.jsdelivr.net/gh/NightSpaceC/live2d-widget@master/autoload.js></script>
<meta property="og:title" content="全连接神经网络浅析">
<meta property="og:description" content="这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成 在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传">
<meta property="og:url" content="https://blog.nightspace.dynv6.net/post/fully-neural-network/">
<meta property="og:site_name" content="Night Space">
<meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="算法"><meta property="article:tag" content="机器学习"><meta property="article:published_time" content="2022-04-15T22:41:00+08:00"><meta property="article:modified_time" content="2022-09-03T22:12:00+08:00">
<meta name=twitter:title content="全连接神经网络浅析">
<meta name=twitter:description content="这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成 在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传">
</head>
<body class=article-page>
<script>(function(){const a='StackColorScheme';localStorage.getItem(a)||localStorage.setItem(a,"auto")})()</script><script>(function(){const b='StackColorScheme',a=localStorage.getItem(b),c=window.matchMedia('(prefers-color-scheme: dark)').matches===!0;a=='dark'||a==='auto'&&c?document.documentElement.dataset.scheme='dark':document.documentElement.dataset.scheme='light'})()</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky">
<button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box>
<span class=hamburger-inner></span>
</span>
</button>
<header>
<figure class=site-avatar>
<a href=/>
<img src=https://avatars.githubusercontent.com/u/63776734 width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a>
</figure>
<div class=site-meta>
<h1 class=site-name><a href=/>Night Space</a></h1>
<h2 class=site-description>为不折腾而折腾，才是折腾的最高境界</h2>
</div>
</header><ol class=social-menu>
<li>
<a href=mailto:NightSpaceC@outlook.com target=_blank title=EMail rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-mail" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="3" y="5" width="18" height="14" rx="2"/><polyline points="3 7 12 13 21 7"/></svg>
</a>
</li>
<li>
<a href=https://github.com/NightSpaceC target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg>
</a>
</li>
<li>
<a href=https://blog.nightspace.dynv6.net/index.xml target=_blank title=RSS rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg>
</a>
</li>
</ol><ol class=menu id=main-menu>
<li>
<a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>首页</span>
</a>
</li>
<li>
<a href=/page/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span>
</a>
</li>
<li>
<a href=/page/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span>
</a>
</li>
<li>
<a href=/page/tools/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-tools" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 21h4L20 8a1.5 1.5.0 00-4-4L3 17v4"/><line x1="14.5" y1="5.5" x2="18.5" y2="9.5"/><polyline points="12 8 7 3 3 7 8 12"/><line x1="7" y1="8" x2="5.5" y2="9.5"/><polyline points="16 12 21 17 17 21 12 16"/><line x1="16" y1="17" x2="14.5" y2="18.5"/></svg>
<span>工具箱</span>
</a>
</li>
<li>
<a href=/page/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span>
</a>
</li>
<div class=menu-bottom-section>
<li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span>
</li>
</div>
</ol>
</aside>
<aside class="sidebar right-sidebar sticky">
<section class="widget archives">
<div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
</div>
<h2 class="widget-title section-title">目录</h2>
<div class=widget--toc>
<nav id=TableOfContents>
<ol>
<li><a href=#神经元>神经元</a></li>
<li><a href=#约定>约定</a></li>
<li><a href=#前向传播>前向传播</a></li>
<li><a href=#训练>训练</a></li>
<li><a href=#反向传播>反向传播</a></li>
<li><a href=#总结>总结</a></li>
<li><a href=#再谈训练>再谈训练</a></li>
<li><a href=#演示代码>演示代码</a></li>
</ol>
</nav>
</div>
</section>
</aside>
<main class="main full-width">
<article class=main-article>
<header class=article-header>
<div class=article-details>
<header class=article-category>
<a href=/categories/%E7%AE%97%E6%B3%95/>
算法
</a>
<a href=/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>
机器学习
</a>
</header>
<div class=article-title-wrapper>
<h2 class=article-title>
<a href=/post/fully-neural-network/>全连接神经网络浅析</a>
</h2>
</div>
<footer class=article-time>
<div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Apr 15, 2022</time>
</div>
<div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>
阅读时长: 6 分钟
</time>
</div>
</footer>
</div>
</header>
<section class=article-content>
<p><img src=/post/fully-neural-network/neural-network-structure.png width=720 height=480 srcset="/post/fully-neural-network/neural-network-structure_hu6b853076bbed57838222879c72405a5c_15085_480x0_resize_box_3.png 480w, /post/fully-neural-network/neural-network-structure_hu6b853076bbed57838222879c72405a5c_15085_1024x0_resize_box_3.png 1024w" loading=lazy alt=全连接神经网络简图 class=gallery-image data-flex-grow=150 data-flex-basis=360px></p>
<p>这是一个全连接神经网络的简图，由一个输入层，两个隐藏层和一个输出层构成</p>
<p>在这篇文章中，我将详细的讲讲它和其它类似的神经网络怎么工作，以及反向传播的完整推导过程</p>
<h1 id=神经元>神经元</h1>
<p>将一个神经元放大来看，大概是这样：</p>
<p><img src=/post/fully-neural-network/neural-structure.png width=720 height=480 srcset="/post/fully-neural-network/neural-structure_hu9c38fb87e073e95a82c5f6142a889900_8443_480x0_resize_box_3.png 480w, /post/fully-neural-network/neural-structure_hu9c38fb87e073e95a82c5f6142a889900_8443_1024x0_resize_box_3.png 1024w" loading=lazy alt=神经元简图 class=gallery-image data-flex-grow=150 data-flex-basis=360px></p>
<p>其中， $w_i$ 是权重， $b$ 是偏置， $f(x)$ 是激活函数</p>
<p>激活函数有很多种，常用的有 Sigmoid, ReLU 等，但它们的目的都是为了增强网络的拟合能力，进行<strong>非线性的拟合</strong></p>
<p><strong>激活函数必须是非线性的</strong></p>
<p>令 $n$ 为输入数量， $x_i$ 为每个输入的值</p>
<p>在激活之前，它的输出为输入加权求和后的值。即 $q=\sum_{i=1}^nw_ix_i+b$</p>
<p>激活之后，它的输出为： $r=f(q)$</p>
<p>请务必记牢这两个式子，后面会频繁地使用它们</p>
<h1 id=约定>约定</h1>
<p>网络层数（不包括输入层）： $T$</p>
<p>网络输入数量： $n_0$</p>
<p>第 $k$ 层神经元数量： $n_k$</p>
<p>第 $k$ 层的激活函数： $f_k(x)$</p>
<p>连接第 $k$ 层第 $i$ 个神经元与上一层第 $j$ 个神经元的权重： $w_{kij}$</p>
<p>第 $k$ 层第 $i$ 个神经元的偏置： $b_{ki}$</p>
<p>网络的第 $i$ 个输入： $r_{0i}$</p>
<p>第 $k$ 层第 $i$ 个神经元激活前的输出： $q_{ki}$</p>
<p>第 $k$ 层第 $i$ 个神经元激活后的输出： $r_{ki}$</p>
<h1 id=前向传播>前向传播</h1>
<p>之前，我们已经知道了每一个神经元的工作方法</p>
<p>那么这一步十分简单，用一样的方法即可</p>
<p>$$q_{ki}=\sum_{j=1}^{n_{k-1}}w_{kij}r_{{k-1}j}+b_{ki}$$</p>
<p>$$r_{ki}=f_k(q_{ki})$$</p>
<p>最后一层神经元激活后的输出，就是整个神经网络的输出</p>
<h1 id=训练>训练</h1>
<p>到目前为止，我们还有一个很大的问题：参数从哪来？</p>
<p>类似于网络层数、神经元数量这些关于网络结构以及之后要说的训练过程的参数，我们称为<strong>超参数</strong></p>
<p>这些参数通常由网络设计者来设定</p>
<p>而权重和偏置，手动设定显然不现实。所以，我们通过让网络自己学习这些参数，这就是<strong>训练</strong></p>
<p>为了训练神经网络，首先要设计一个损失函数，用来评估模型的准确度</p>
<p>如 $L(x_1, x_2, &mldr; x_{n_T}, y_1, y_2, &mldr; y_{n_T})=\sum_{i=1}^{n_T}(x_i-y_i)^2$ 就是一种常用的损失函数</p>
<p>我们令期望输出的第 $i$ 个值为 $y_i$</p>
<p>我们令损失值 $l=L(r_{T1}, r_{T2}, &mldr; r_{Tn_T}, y_1, y_2, &mldr; y_{n_T})$</p>
<p>想要找到最合适的参数，就是找到 $l$ 的低谷</p>
<p>我们可以通过一些方法求出 $\dfrac{\partial l}{\partial w_{kij}}$ 和 $\dfrac{\partial l}{\partial b_{ki}}$</p>
<p>求出了微分，我们就能够知道如何调整参数才能让 $l$ 尽可能快地减小</p>
<p>这就是<strong>梯度下降法</strong></p>
<p>我们使用<strong>优化器</strong>这一概念来描述调整的方法，我们令其为 $O(w, d, \eta)$</p>
<p>最简单的一种就是 $O(w, d, \eta)=w-\eta d$</p>
<p>其中的 $\eta$ 指学习率，这也是个超参数</p>
<p>通常情况下，太高的学习率会导致损失值不稳定，太低会导致学习过慢</p>
<p>一般，我们可以取 $\eta=0.01$</p>
<p>这样一来，只需不断使</p>
<p>$$w_{kij}\gets O\left(w_{kij}, \dfrac{\partial l}{\partial w_{kij}}, \eta\right)$$</p>
<p>$$b_{ki}\gets O\left(b_{ki}, \dfrac{\partial l}{\partial b_{ki}}, \eta\right)$$</p>
<p>就可以得到较优的参数</p>
<h1 id=反向传播>反向传播</h1>
<p>现在，我们来说说如何求出 $\dfrac{\partial l}{\partial w_{kij}}$ 和 $\dfrac{\partial l}{\partial b_{ki}}$ ，这也是最难的一部分</p>
<p><strong>高能预警，请有一定的微分基础后再往下读</strong></p>
<p>首先，根据 $q_{ki}=\sum_{j=1}^{n_{k-1}}w_{kij}r_{{k-1}j}+b_{ki}$ ，我们得出</p>
<p>$$
\begin{align*}
\dfrac{\partial l}{\partial w_{kij}}&=\dfrac{\partial l}{\partial q_{ki}}\cdot\dfrac{\partial q_{ki}}{\partial w_{kij}}\\
&=\dfrac{\partial l}{\partial q_{ki}}\cdot r_{{k-1}j}
\end{align*}
$$</p>
<p>$$
\begin{align*}
\dfrac{\partial l}{\partial b_{ki}}&=\dfrac{\partial l}{\partial q_{ki}}\cdot\dfrac{\partial q_{ki}}{\partial b_{ki}}\\
&=\dfrac{\partial l}{\partial q_{ki}}
\end{align*}
$$</p>
<p>$$
\begin{align*}
\dfrac{\partial l}{\partial q_{ki}}&=\sum_{j=1}^{n_{k+1}}\dfrac{\partial l}{\partial q_{{k+1}j}}\cdot\dfrac{\partial q_{{k+1}j}}{\partial r_{ki}}\cdot\dfrac{\partial r_{ki}}{\partial q_{ki}}\\
&=\sum_{j=1}^{n_{k+1}}\dfrac{\partial l}{\partial q_{{k+1}j}}\cdot w_{{k+1}ji}\cdot f_k^{'}(q_{ki})\\
&=\left(\sum_{j=1}^{n_{k+1}}\dfrac{\partial l}{\partial q_{{k+1}j}}\cdot w_{{k+1}ji}\right)\cdot f_k^{'}(q_{ki})
\end{align*}
$$</p>
<p>根据 $l=L(r_{T1}, r_{T2}, &mldr; r_{Tn_T}, y_1, y_2, &mldr; y_{n_T})$ ，可以得出</p>
<p>$$
\begin{align*}
\dfrac{\partial l}{\partial q_{Ti}}&=\dfrac{\partial l}{\partial r_{Ti}}\cdot\dfrac{\partial r_{Ti}}{\partial q_{Ti}}\\
&=\dfrac{\partial l}{\partial r_{Ti}}\cdot f_T^{'}(q_{Ti})
\end{align*}
$$</p>
<p>得出了这几条公式，我们就能从后往前算出所有的 $\dfrac{\partial l}{\partial q_{ki}}$ ，再用它们求出所有的 $\dfrac{\partial l}{\partial w_{kij}}$ 和 $\dfrac{\partial l}{\partial b_{ki}}$ ，用来进行梯度下降</p>
<h1 id=总结>总结</h1>
<p>总结起来，重要的公式无外乎这几个：</p>
<p>$$q_{ki}=\sum_{j=1}^{n_{k-1}}w_{kij}r_{{k-1}j}+b_{ki}$$</p>
<p>$$r_{ki}=f_k(q_{ki})$$</p>
<p>$$l=L(r_{T1}, r_{T2}, &mldr; r_{Tn_T}, y_1, y_2, &mldr; y_{n_T})$$</p>
<p>$$\dfrac{\partial l}{\partial q_{Ti}}=\dfrac{\partial l}{\partial r_{Ti}}\cdot f_T^{'}(q_{Ti})$$</p>
<p>$$\dfrac{\partial l}{\partial q_{ki}}=\left(\sum_{j=1}^{n_{k+1}}\dfrac{\partial l}{\partial q_{{k+1}j}}\cdot w_{{k+1}ji}\right)\cdot f_k^{'}(q_{ki})$$</p>
<p>$$\dfrac{\partial l}{\partial w_{kij}}=\dfrac{\partial l}{\partial q_{ki}}\cdot r_{{k-1}j}$$</p>
<p>$$\dfrac{\partial l}{\partial b_{ki}}=\dfrac{\partial l}{\partial q_{ki}}$$</p>
<p>$$w_{kij}\gets O\left(w_{kij}, \dfrac{\partial l}{\partial w_{kij}}, \eta\right)$$</p>
<p>$$b_{ki}\gets O\left(b_{ki}, \dfrac{\partial l}{\partial b_{ki}}, \eta\right)$$</p>
<h1 id=再谈训练>再谈训练</h1>
<p>在训练一个模型时，需要将数据集分成两部分：训练集和测试集</p>
<p>测试集不能以任何形式参与训练，仅用于测试模型准确性</p>
<p>若模型在训练集上表现优异，但在测试集上表现不佳，可能是出现了<strong>过拟合</strong>，这时可以通过减少网络层数和增加训练集的数据量来解决</p>
<p>另一种解决方法是使用正则化</p>
<p>以L2正则化为例，它会使用</p>
<p>$$J(\lambda, w_{111}, w_{112}, &mldr; w_{Tn_Tn_{T-1}}, b_{11}, b_{12}, &mldr; b_{Tn_T}, x_1, x_2, &mldr; x_{n_T}, y_1, y_2, &mldr; y_{n_T})=L(x_1, x_2, &mldr; x_{n_T}, y_1, y_2, &mldr; y_{n_T})+\lambda(\sum_{k=1}^{T}\sum_{i=1}^{n_k}\sum_{j=1}^{n_{k-1}}w_{kij}^2+\sum_{k=1}^{T}\sum_{i=1}^{n_k}b_{ki}^2)$$</p>
<p>替代原本的损失函数，其中 $L(x_1, x_2, &mldr; x_{n_T}, y_1, y_2, &mldr; y_{n_T})$ 是原本的损失函数， $w$ 和 $b$ 是网络的边权和偏置</p>
<p>同时求微分公式改为</p>
<p>$$\dfrac{\partial l}{\partial w_{kij}}=\dfrac{\partial l}{\partial q_{ki}}\cdot r_{{k-1}j}+2\lambda w_{kij}$$</p>
<p>$$\dfrac{\partial l}{\partial b_{ki}}=\dfrac{\partial l}{\partial q_{ki}}+2\lambda b_{ki}$$</p>
<p>$\lambda$ 是正则化因子，是超参数</p>
<p>$\lambda$ 值越大，网络中的参数会偏向于更小以降低损失值，同时防止过拟合</p>
<p>还有一种常用的正则化方法 Dropout ，它通过在训练时随机忽略一部分神经元来防止过拟合，读者可以自行了解</p>
<h1 id=演示代码>演示代码</h1>
<p>这份代码实现了一个分类器，并用异或问题进行测试</p>
<p>它不支持正则化和不同的激活函数</p>
<p>年代久远，风格不一致请见谅</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span><span class=lnt>248
</span><span class=lnt>249
</span><span class=lnt>250
</span><span class=lnt>251
</span><span class=lnt>252
</span><span class=lnt>253
</span><span class=lnt>254
</span><span class=lnt>255
</span><span class=lnt>256
</span><span class=lnt>257
</span><span class=lnt>258
</span><span class=lnt>259
</span><span class=lnt>260
</span><span class=lnt>261
</span><span class=lnt>262
</span><span class=lnt>263
</span><span class=lnt>264
</span><span class=lnt>265
</span><span class=lnt>266
</span><span class=lnt>267
</span><span class=lnt>268
</span><span class=lnt>269
</span><span class=lnt>270
</span><span class=lnt>271
</span><span class=lnt>272
</span><span class=lnt>273
</span><span class=lnt>274
</span><span class=lnt>275
</span><span class=lnt>276
</span><span class=lnt>277
</span><span class=lnt>278
</span><span class=lnt>279
</span><span class=lnt>280
</span><span class=lnt>281
</span><span class=lnt>282
</span><span class=lnt>283
</span><span class=lnt>284
</span><span class=lnt>285
</span><span class=lnt>286
</span><span class=lnt>287
</span><span class=lnt>288
</span><span class=lnt>289
</span><span class=lnt>290
</span><span class=lnt>291
</span><span class=lnt>292
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=cp>#include</span><span class=cpf>&lt;vector&gt;</span><span class=cp>
</span><span class=cp>#include</span><span class=cpf>&lt;random&gt;</span><span class=cp>
</span><span class=cp>#include</span><span class=cpf>&lt;functional&gt;</span><span class=cp>
</span><span class=cp></span><span class=k>class</span> <span class=nc>FeedforwardNeuralNetwork</span>
<span class=p>{</span>
    <span class=k>public</span><span class=o>:</span>
        <span class=n>FeedforwardNeuralNetwork</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>inNum</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>unsigned</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>neuralNum</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunction</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunctionDerivative</span><span class=p>);</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>calculate</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
        <span class=kt>void</span> <span class=nf>train</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>);</span>
    <span class=k>private</span><span class=o>:</span>
        <span class=k>class</span> <span class=nc>NeuralLayer</span>
        <span class=p>{</span>
            <span class=k>public</span><span class=o>:</span>
                <span class=n>NeuralLayer</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>neuralNumForLastLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>neuralNumForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunction</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunctionDerivative</span><span class=p>);</span>
                <span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>forward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForLastLayer</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
                <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>inForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
                <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>inForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>weightForNextLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForNextLayer</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
                <span class=kt>void</span> <span class=nf>adjust</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForLastLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>);</span>
                <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>weight</span><span class=p>;</span>
                <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>bias</span><span class=p>;</span>
                <span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=n>activationFunction</span><span class=p>;</span>
                <span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=n>activationFunctionDerivative</span><span class=p>;</span>
        <span class=p>};</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>forward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>ans</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>)</span> <span class=k>const</span><span class=p>;</span>
        <span class=kt>void</span> <span class=nf>adjust</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForEachLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForEachLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>);</span>
    <span class=k>public</span><span class=o>:</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>NeuralLayer</span><span class=o>&gt;</span> <span class=n>layer</span><span class=p>;</span>
<span class=p>};</span>
<span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>FeedforwardNeuralNetwork</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>inNum</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>unsigned</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>neuralNum</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunction</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>activationFunctionDerivative</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>neuralNum</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=n>layer</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>i</span><span class=o>&lt;</span><span class=mi>2</span><span class=o>?</span><span class=n>NeuralLayer</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=n>inNum</span><span class=p>,</span><span class=n>neuralNum</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span><span class=n>activationFunction</span><span class=p>,</span><span class=n>activationFunctionDerivative</span><span class=p>)</span><span class=o>:</span><span class=n>NeuralLayer</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=n>neuralNum</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>2</span><span class=p>),</span><span class=n>neuralNum</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span><span class=n>activationFunction</span><span class=p>,</span><span class=n>activationFunctionDerivative</span><span class=p>));</span>
<span class=p>}</span>
<span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>calculate</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>)</span> <span class=k>const</span>    <span class=c1>//输出最终结果
</span><span class=c1></span><span class=p>{</span>
    <span class=k>return</span> <span class=nf>forward</span><span class=p>(</span><span class=n>in</span><span class=p>).</span><span class=n>back</span><span class=p>().</span><span class=n>second</span><span class=p>;</span>
<span class=p>}</span>
<span class=kt>void</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>train</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>)</span>
<span class=p>{</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>ans</span><span class=o>=</span><span class=n>forward</span><span class=p>(</span><span class=n>in</span><span class=p>);</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>gradient</span><span class=o>=</span><span class=n>backward</span><span class=p>(</span><span class=n>ans</span><span class=p>,</span><span class=n>desiredOut</span><span class=p>);</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>outForEachLayer</span><span class=p>;</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=n>outForEachLayer</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>);</span>
    <span class=n>adjust</span><span class=p>(</span><span class=n>in</span><span class=p>,</span><span class=n>outForEachLayer</span><span class=p>,</span><span class=n>gradient</span><span class=p>,</span><span class=n>learningRate</span><span class=p>);</span>
<span class=p>}</span>
<span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>neuralNumForLastLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>neuralNumForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>_activationFunction</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>function</span><span class=o>&lt;</span><span class=kt>double</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span><span class=o>&amp;</span><span class=p>)</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>_activationFunctionDerivative</span><span class=p>)</span><span class=o>:</span>
    <span class=n>activationFunction</span><span class=p>(</span><span class=n>_activationFunction</span><span class=p>),</span>
    <span class=n>activationFunctionDerivative</span><span class=p>(</span><span class=n>_activationFunctionDerivative</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>neuralNumForThisLayer</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
    <span class=p>{</span>
        <span class=n>weight</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>());</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>neuralNumForLastLayer</span><span class=p>;</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
            <span class=n>weight</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>].</span><span class=n>push_back</span><span class=p>((</span><span class=o>*</span><span class=n>randomNumberGeneration</span><span class=p>)()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>2.0</span><span class=o>-</span><span class=mf>1.0</span><span class=p>);</span>
        <span class=n>bias</span><span class=p>.</span><span class=n>push_back</span><span class=p>((</span><span class=o>*</span><span class=n>randomNumberGeneration</span><span class=p>)()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>2.0</span><span class=o>-</span><span class=mf>1.0</span><span class=p>);</span>
    <span class=p>}</span>
<span class=p>}</span>
<span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>forward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForLastLayer</span><span class=p>)</span> <span class=k>const</span>    <span class=c1>//前向传播
</span><span class=c1></span><span class=p>{</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>in</span><span class=p>;</span> <span class=c1>//激活前
</span><span class=c1></span>    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>;</span><span class=c1>//激活后
</span><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
    <span class=p>{</span>
        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
            <span class=n>in</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>+=</span><span class=n>outForLastLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
        <span class=n>in</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>+=</span><span class=n>bias</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
        <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>activationFunction</span><span class=p>(</span><span class=n>in</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]));</span>
    <span class=p>}</span>
    <span class=k>return</span> <span class=nf>make_pair</span><span class=p>(</span><span class=n>in</span><span class=p>,</span><span class=n>out</span><span class=p>);</span>
<span class=p>}</span>
<span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>inForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>)</span> <span class=k>const</span>   <span class=c1>//计算输出层局部微分
</span><span class=c1></span><span class=p>{</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>gradient</span><span class=p>;</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=n>gradient</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=p>(</span><span class=n>outForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>desiredOut</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span><span class=o>*</span><span class=n>activationFunctionDerivative</span><span class=p>(</span><span class=n>inForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)));</span>
    <span class=k>return</span> <span class=n>gradient</span><span class=p>;</span>
<span class=p>}</span>
<span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>inForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>weightForNextLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForNextLayer</span><span class=p>)</span> <span class=k>const</span>    <span class=c1>//计算隐藏层局部微分
</span><span class=c1></span><span class=p>{</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>gradient</span><span class=p>;</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=n>gradient</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weightForNextLayer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>weightForNextLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
            <span class=n>gradient</span><span class=p>[</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>+=</span><span class=n>weightForNextLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>gradientForNextLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>gradient</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=n>gradient</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>*=</span><span class=n>activationFunctionDerivative</span><span class=p>(</span><span class=n>inForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
    <span class=k>return</span> <span class=n>gradient</span><span class=p>;</span>
<span class=p>}</span>
<span class=kt>void</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>NeuralLayer</span><span class=o>::</span><span class=n>adjust</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForLastLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForThisLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>)</span>   <span class=c1>//调整参数
</span><span class=c1></span><span class=p>{</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
            <span class=n>weight</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>][</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>-=</span><span class=n>learningRate</span><span class=o>*</span><span class=n>gradientForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>outForLastLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>bias</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=n>bias</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>-=</span><span class=n>learningRate</span><span class=o>*</span><span class=n>gradientForThisLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
<span class=p>}</span>
<span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>forward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>)</span> <span class=k>const</span>
<span class=p>{</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>ans</span><span class=p>;</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=n>ans</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>forward</span><span class=p>(</span><span class=n>i</span><span class=o>&lt;</span><span class=mi>2</span><span class=o>?</span><span class=nl>in</span><span class=p>:</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>2</span><span class=p>).</span><span class=n>second</span><span class=p>));</span>
    <span class=k>return</span> <span class=n>ans</span><span class=p>;</span>
<span class=p>}</span>
<span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>backward</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>ans</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>desiredOut</span><span class=p>)</span> <span class=k>const</span>
<span class=p>{</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>gradient</span><span class=p>;</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>&gt;=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>--</span><span class=p>)</span>
        <span class=k>if</span><span class=p>(</span><span class=n>i</span><span class=o>==</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>())</span>
            <span class=n>gradient</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>backward</span><span class=p>(</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>,</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>,</span><span class=n>desiredOut</span><span class=p>));</span>
        <span class=k>else</span>
            <span class=n>gradient</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>backward</span><span class=p>(</span><span class=n>ans</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>,</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=p>).</span><span class=n>weight</span><span class=p>,</span><span class=n>gradient</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>()</span><span class=o>-</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>)));</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>j</span><span class=o>=</span><span class=n>gradient</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>&lt;</span><span class=n>j</span><span class=p>;</span><span class=n>i</span><span class=o>++</span><span class=p>,</span><span class=n>j</span><span class=o>--</span><span class=p>)</span>
        <span class=n>swap</span><span class=p>(</span><span class=n>gradient</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span><span class=n>gradient</span><span class=p>[</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>]);</span>
    <span class=k>return</span> <span class=n>gradient</span><span class=p>;</span>
<span class=p>}</span>
<span class=kt>void</span> <span class=n>FeedforwardNeuralNetwork</span><span class=o>::</span><span class=n>adjust</span><span class=p>(</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>in</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>outForEachLayer</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>gradientForEachLayer</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=n>layer</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>].</span><span class=n>adjust</span><span class=p>(</span><span class=n>i</span><span class=o>&lt;</span><span class=mi>2</span><span class=o>?</span><span class=nl>in</span><span class=p>:</span><span class=n>outForEachLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>2</span><span class=p>),</span><span class=n>gradientForEachLayer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span><span class=n>learningRate</span><span class=p>);</span>
<span class=p>}</span>
<span class=cp>#include</span><span class=cpf>&lt;math.h&gt;</span><span class=cp>
</span><span class=cp>#define E 2.7182818284590452353602874713526624977572470936999595749669676277240766303535475945713821785251664274
</span><span class=cp></span><span class=kt>double</span> <span class=nf>Sigmoid</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>return</span> <span class=mf>1.0</span><span class=o>/</span><span class=p>(</span><span class=mf>1.0</span><span class=o>+</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=o>-</span><span class=n>a</span><span class=p>));</span>
<span class=p>}</span>
<span class=kt>double</span> <span class=nf>SigmoidDerivative</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>return</span> <span class=n>Sigmoid</span><span class=p>(</span><span class=n>a</span><span class=p>)</span><span class=o>*</span><span class=p>(</span><span class=mi>1</span><span class=o>-</span><span class=n>Sigmoid</span><span class=p>(</span><span class=n>a</span><span class=p>));</span>
<span class=p>}</span>
<span class=cp>#undef E
</span><span class=cp>#include</span><span class=cpf>&lt;math.h&gt;</span><span class=cp>
</span><span class=cp>#define E 2.7182818284590452353602874713526624977572470936999595749669676277240766303535475945713821785251664274
</span><span class=cp></span><span class=kt>double</span> <span class=nf>Tanh</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>return</span> <span class=p>(</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=n>a</span><span class=p>)</span><span class=o>-</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=o>-</span><span class=n>a</span><span class=p>))</span><span class=o>/</span><span class=p>(</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=n>a</span><span class=p>)</span><span class=o>+</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=o>-</span><span class=n>a</span><span class=p>));</span>
<span class=p>}</span>
<span class=kt>double</span> <span class=nf>TanhDerivative</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>return</span> <span class=p>(</span><span class=mf>4.0</span><span class=o>*</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=mf>2.0</span><span class=o>*</span><span class=n>a</span><span class=p>))</span><span class=o>/</span><span class=p>((</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=mf>2.0</span><span class=o>*</span><span class=n>a</span><span class=p>)</span><span class=o>+</span><span class=mf>1.0</span><span class=p>)</span><span class=o>*</span><span class=p>(</span><span class=n>pow</span><span class=p>(</span><span class=n>E</span><span class=p>,</span><span class=mf>2.0</span><span class=o>*</span><span class=n>a</span><span class=p>)</span><span class=o>+</span><span class=mf>1.0</span><span class=p>));</span>
<span class=p>}</span>
<span class=cp>#undef E
</span><span class=cp></span><span class=kt>double</span> <span class=nf>ReLU</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>if</span><span class=p>(</span><span class=n>a</span><span class=o>&gt;</span><span class=mf>0.0</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>a</span><span class=p>;</span>
    <span class=k>else</span>
        <span class=k>return</span> <span class=mf>0.0</span><span class=p>;</span>
<span class=p>}</span>
<span class=kt>double</span> <span class=nf>ReLUDerivative</span><span class=p>(</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>a</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>if</span><span class=p>(</span><span class=n>a</span><span class=o>&gt;=</span><span class=mf>0.0</span><span class=p>)</span>
        <span class=k>return</span> <span class=mf>1.0</span><span class=p>;</span>
    <span class=k>else</span>
        <span class=k>return</span> <span class=mf>0.0</span><span class=p>;</span>
<span class=p>}</span>
<span class=cp>#include</span><span class=cpf>&lt;stdio.h&gt;</span><span class=cp>
</span><span class=cp></span><span class=kt>void</span> <span class=nf>printNetwork</span><span class=p>(</span><span class=k>const</span> <span class=n>FeedforwardNeuralNetwork</span> <span class=o>&amp;</span><span class=n>network</span><span class=p>)</span>
<span class=p>{</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
    <span class=p>{</span>
        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Layer %u:</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>i</span><span class=p>);</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>weight</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
        <span class=p>{</span>
            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;    Node %u:</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>j</span><span class=p>);</span>
            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;        Weight:&#34;</span><span class=p>);</span>
            <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>k</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>k</span><span class=o>&lt;=</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>size</span><span class=p>();</span><span class=n>k</span><span class=o>++</span><span class=p>)</span>
                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf &#34;</span><span class=p>,</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>weight</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>at</span><span class=p>(</span><span class=n>k</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;        Bias:%lf</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>network</span><span class=p>.</span><span class=n>layer</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>bias</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
        <span class=p>}</span>
    <span class=p>}</span>
    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
<span class=p>}</span>
<span class=kt>void</span> <span class=nf>train</span><span class=p>(</span><span class=n>FeedforwardNeuralNetwork</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>network</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>trainSet</span><span class=p>,</span><span class=k>const</span> <span class=kt>double</span> <span class=o>&amp;</span><span class=n>learningRate</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>roundNum</span><span class=p>,</span><span class=k>const</span> <span class=kt>unsigned</span> <span class=o>&amp;</span><span class=n>frequency</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=p>{</span>
    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Start train</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>k</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>k</span><span class=o>&lt;=</span><span class=n>roundNum</span><span class=p>;</span><span class=n>k</span><span class=o>++</span><span class=p>)</span>
    <span class=p>{</span>
        <span class=kt>double</span> <span class=n>loss</span><span class=o>=</span><span class=mf>0.0</span><span class=p>;</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>trainSet</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
        <span class=p>{</span>
            <span class=n>network</span><span class=o>-&gt;</span><span class=n>train</span><span class=p>(</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>,</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>,</span><span class=n>learningRate</span><span class=p>);</span>
            <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>(</span><span class=n>network</span><span class=o>-&gt;</span><span class=n>calculate</span><span class=p>(</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>));</span>
            <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>out</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
                <span class=n>loss</span><span class=o>+=</span><span class=p>(</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span><span class=o>*</span><span class=p>(</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
            <span class=k>if</span><span class=p>(</span><span class=n>k</span><span class=o>%</span><span class=n>frequency</span><span class=o>==</span><span class=mi>0</span><span class=p>)</span>
            <span class=p>{</span>
                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;In:[&#34;</span><span class=p>);</span>
                <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
                    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n</span><span class=s>Desired Out:[&#34;</span><span class=p>);</span>
                <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
                    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>trainSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n</span><span class=s>Out:[&#34;</span><span class=p>);</span>
                <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>out</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
                    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
                <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n\n</span><span class=s>&#34;</span><span class=p>);</span>
            <span class=p>}</span>
        <span class=p>}</span>
        <span class=n>loss</span><span class=o>/=</span><span class=n>trainSet</span><span class=p>.</span><span class=n>size</span><span class=p>();</span>
        <span class=k>if</span><span class=p>(</span><span class=n>k</span><span class=o>%</span><span class=n>frequency</span><span class=o>==</span><span class=mi>0</span><span class=p>)</span>
        <span class=p>{</span>
            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Loss:%lf</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>loss</span><span class=p>);</span>
            <span class=n>printNetwork</span><span class=p>(</span><span class=o>*</span><span class=n>network</span><span class=p>);</span>
        <span class=p>}</span>
    <span class=p>}</span>
    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Finished train</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
<span class=p>}</span>
<span class=kt>void</span> <span class=nf>test</span><span class=p>(</span><span class=n>FeedforwardNeuralNetwork</span> <span class=o>*</span><span class=k>const</span> <span class=o>&amp;</span><span class=n>network</span><span class=p>,</span><span class=k>const</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>testSet</span><span class=p>)</span>
<span class=p>{</span>
    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Start test</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
    <span class=kt>double</span> <span class=n>loss</span><span class=o>=</span><span class=mf>0.0</span><span class=p>;</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>testSet</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>i</span><span class=o>++</span><span class=p>)</span>
    <span class=p>{</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>(</span><span class=n>network</span><span class=o>-&gt;</span><span class=n>calculate</span><span class=p>(</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>));</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>out</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
            <span class=n>loss</span><span class=o>+=</span><span class=p>(</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span><span class=o>*</span><span class=p>(</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>-</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;In:[&#34;</span><span class=p>);</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>first</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n</span><span class=s>Desired Out:[&#34;</span><span class=p>);</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>testSet</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>).</span><span class=n>second</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n</span><span class=s>Out:[&#34;</span><span class=p>);</span>
        <span class=k>for</span><span class=p>(</span><span class=kt>unsigned</span> <span class=n>j</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>j</span><span class=o>&lt;=</span><span class=n>out</span><span class=p>.</span><span class=n>size</span><span class=p>();</span><span class=n>j</span><span class=o>++</span><span class=p>)</span>
            <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%lf,&#34;</span><span class=p>,</span><span class=n>out</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;]</span><span class=se>\n\n</span><span class=s>&#34;</span><span class=p>);</span>
    <span class=p>}</span>
    <span class=n>loss</span><span class=o>/=</span><span class=n>testSet</span><span class=p>.</span><span class=n>size</span><span class=p>();</span>
    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Loss:%lf</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span><span class=n>loss</span><span class=p>);</span>
    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;Finished test</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
<span class=p>}</span>
<span class=cp>#include</span> <span class=cpf>&lt;ctime&gt;</span><span class=cp>
</span><span class=cp>#include</span> <span class=cpf>&lt;random&gt;</span><span class=cp>
</span><span class=cp></span><span class=kt>int</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
    <span class=n>std</span><span class=o>::</span><span class=n>mt19937</span> <span class=n>randomNumberGeneration</span><span class=p>(</span><span class=n>time</span><span class=p>(</span><span class=k>nullptr</span><span class=p>));</span>
    <span class=kt>unsigned</span> <span class=n>inNum</span> <span class=o>=</span> <span class=mi>2</span><span class=p>;</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>unsigned</span><span class=o>&gt;</span> <span class=n>neuralNum</span><span class=p>;</span>
    <span class=n>neuralNum</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mi>3</span><span class=p>);</span>
    <span class=n>neuralNum</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mi>3</span><span class=p>);</span>
    <span class=n>neuralNum</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mi>1</span><span class=p>);</span>
    <span class=n>FeedforwardNeuralNetwork</span> <span class=n>network</span><span class=p>(</span><span class=o>&amp;</span><span class=n>randomNumberGeneration</span><span class=p>,</span> <span class=n>inNum</span><span class=p>,</span> <span class=n>neuralNum</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>bind</span><span class=p>(</span><span class=n>Sigmoid</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>placeholders</span><span class=o>::</span><span class=n>_1</span><span class=p>),</span> <span class=n>std</span><span class=o>::</span><span class=n>bind</span><span class=p>(</span><span class=n>SigmoidDerivative</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>placeholders</span><span class=o>::</span><span class=n>_1</span><span class=p>));</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>trainSet</span><span class=p>;</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;=</span> <span class=mi>10000</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>in</span><span class=p>;</span>
        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>20.0</span><span class=o>-</span><span class=mf>10.0</span><span class=p>);</span>
        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>20.0</span><span class=o>-</span><span class=mf>10.0</span><span class=p>);</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>;</span>
        <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
            <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>1.0</span><span class=p>);</span>
            <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
            <span class=p>}</span>
        <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
            <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
            <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>1.0</span><span class=p>);</span>
            <span class=p>}</span>
        <span class=p>}</span>
        <span class=n>trainSet</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>make_pair</span><span class=p>(</span><span class=n>in</span><span class=p>,</span> <span class=n>out</span><span class=p>));</span>
    <span class=p>}</span>
    <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>pair</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span><span class=p>,</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=o>&gt;</span> <span class=o>&gt;</span> <span class=n>testSet</span><span class=p>;</span>
    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;=</span> <span class=mi>50</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>in</span><span class=p>;</span>
        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>20.0</span><span class=o>-</span><span class=mf>10.0</span><span class=p>);</span>
        <span class=n>in</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>randomNumberGeneration</span><span class=p>()</span><span class=o>/</span><span class=p>(</span><span class=kt>double</span><span class=p>)</span><span class=mh>0xffffffff</span><span class=o>*</span><span class=mf>20.0</span><span class=o>-</span><span class=mf>10.0</span><span class=p>);</span>
        <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>double</span><span class=o>&gt;</span> <span class=n>out</span><span class=p>;</span>
        <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
            <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>1.0</span><span class=p>);</span>
            <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
            <span class=p>}</span>
        <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
            <span class=k>if</span><span class=p>(</span><span class=n>in</span><span class=p>.</span><span class=n>at</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>)</span> <span class=p>{</span>
                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>0.0</span><span class=p>);</span>
            <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
                <span class=n>out</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=mf>1.0</span><span class=p>);</span>
            <span class=p>}</span>
        <span class=p>}</span>
        <span class=n>testSet</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>std</span><span class=o>::</span><span class=n>make_pair</span><span class=p>(</span><span class=n>in</span><span class=p>,</span> <span class=n>out</span><span class=p>));</span>
    <span class=p>}</span>
    <span class=n>train</span><span class=p>(</span><span class=o>&amp;</span><span class=n>network</span><span class=p>,</span> <span class=n>trainSet</span><span class=p>,</span> <span class=mf>0.03</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>10</span><span class=p>);</span>
    <span class=n>test</span><span class=p>(</span><span class=o>&amp;</span><span class=n>network</span><span class=p>,</span> <span class=n>testSet</span><span class=p>);</span>
<span class=p>}</span>
</code></pre></td></tr></table>
</div>
</div>
</section>
<footer class=article-footer>
<section class=article-tags>
<a href=/tags/%E7%AE%97%E6%B3%95/>算法</a>
<a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a>
</section>
<section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>署名-非商业性使用-相同方式共享 4.0 国际</a></span>
</section>
<section class=article-lastmod><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>
最后更新于 Sep 03, 2022 22:12 +0800
</span>
</section></footer>
<link rel=stylesheet href=https://gcore.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://gcore.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://gcore.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script>
</article>
<aside class=related-content--wrapper>
<h2 class=section-title>相关文章</h2>
<div class=related-content>
<div class="flex article-list--tile">
<article>
<a href=/post/linear-regression/>
<div class=article-details>
<h2 class=article-title>线性回归</h2>
</div>
</a>
</article>
<article>
<a href=/post/solution-p2831/>
<div class=article-details>
<h2 class=article-title>P2831 [NOIP2016 提高组] 愤怒的小鸟</h2>
</div>
</a>
</article>
<article>
<a href=/post/solution-p2013/>
<div class=article-details>
<h2 class=article-title>P2013 无线电测向</h2>
</div>
</a>
</article>
<article>
<a href=/post/miller-rabin/>
<div class=article-details>
<h2 class=article-title>Miller Rabin 素性测试</h2>
</div>
</a>
</article>
<article>
<a href=/post/solution-p4825/>
<div class=article-details>
<h2 class=article-title>P4825 【[USACO15FEB]Cow Hopscotch S】</h2>
</div>
</a>
</article>
</div>
</div>
</aside>
<script src=https://giscus.app/client.js data-repo=NightSpaceC/blog data-repo-id=R_kgDOH7TGUA data-category=giscus data-category-id=DIC_kwDOH7TGUM4CRMRD data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=zh-CN crossorigin=anonymous async></script>
<script>function setGiscusTheme(b){let a=document.querySelector("iframe.giscus-frame");a&&a.contentWindow.postMessage({giscus:{setConfig:{theme:b}}},"https://giscus.app")}(function(){addEventListener("message",b=>{if(event.origin!=="https://giscus.app")return;a()}),window.addEventListener("onColorSchemeChange",a);function a(){document.documentElement.dataset.scheme==="light"?setGiscusTheme('light'):setGiscusTheme('dark')}})()</script>
<footer class=site-footer>
<section class=copyright>
&copy;
2021 -
2023 Night Space
</section>
<section class=powerby>
Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> <br>
主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.17.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计
</section>
</footer>
<div class=pswp tabindex=-1 role=dialog aria-hidden=true>
<div class=pswp__bg></div>
<div class=pswp__scroll-wrap>
<div class=pswp__container>
<div class=pswp__item></div>
<div class=pswp__item></div>
<div class=pswp__item></div>
</div>
<div class="pswp__ui pswp__ui--hidden">
<div class=pswp__top-bar>
<div class=pswp__counter></div>
<button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
<div class=pswp__preloader>
<div class=pswp__preloader__icn>
<div class=pswp__preloader__cut>
<div class=pswp__preloader__donut></div>
</div>
</div>
</div>
</div>
<div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
<div class=pswp__share-tooltip></div>
</div>
<button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
</button>
<div class=pswp__caption>
<div class=pswp__caption__center></div>
</div>
</div>
</div>
</div><script src=https://gcore.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://gcore.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous>
</main>
</div>
<script src=https://gcore.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const a=document.createElement('link');a.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",a.type="text/css",a.rel="stylesheet",document.head.appendChild(a)})()</script>
<script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "58e4125f7abc491fa8a29447400d8df1"}'></script>
</body>
</html>